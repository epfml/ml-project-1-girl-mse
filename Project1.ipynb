{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b930523-c9c4-4b69-a5e0-44e3caa05b2b",
   "metadata": {},
   "source": [
    "# Loading the data\n",
    "\n",
    "First, we are going to load the data that we'll feed to our alorithm in order for it to learn. We have 3 .csv files to import: <br> *x_train.csv*, *x_test.csv* and *y_train.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21237998-1a1c-4363-bb8d-16b0c387c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "\n",
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"/Users/sarazatezalo/Documents/EPFL/semester 1/ML_course/projects/project1/data/dataset_to_release\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1519b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import preprocess_data\n",
    "from implementations import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0898330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "x_train_pp, x_test_pp, y_train_pp, y_test_pp = preprocess_data(x_train, y_train, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a380c255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28975\n",
      "25961\n",
      "25961\n"
     ]
    }
   ],
   "source": [
    "print(np.sum((y_train==1).astype(int)))\n",
    "print(np.sum((y_train_pp==1).astype(int)))\n",
    "print(np.sum((y_train_pp==0).astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "693c6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:204: RuntimeWarning: overflow encountered in exp\n",
      "  loss = -np.dot(np.transpose(y), np.dot(tx,w)) + np.sum(np.log(np.ones(N,) + np.exp(np.dot(tx,w))))\n",
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:186: RuntimeWarning: overflow encountered in exp\n",
      "  return np.divide(np.exp(t),(1+np.exp(t)))\n",
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:186: RuntimeWarning: invalid value encountered in divide\n",
      "  return np.divide(np.exp(t),(1+np.exp(t)))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/Project1.ipynb Cell 6\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sarazatezalo/Documents/EPFL/semester%201/ml-project-1-girl-mse/Project1.ipynb#X25sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m gamma \u001b[39m=\u001b[39m \u001b[39m0.01\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sarazatezalo/Documents/EPFL/semester%201/ml-project-1-girl-mse/Project1.ipynb#X25sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m max_iters \u001b[39m=\u001b[39m \u001b[39m2000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sarazatezalo/Documents/EPFL/semester%201/ml-project-1-girl-mse/Project1.ipynb#X25sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m w, loss \u001b[39m=\u001b[39m logistic_regression(y_train_pp, x_train_pp, initial_w, max_iters, gamma)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sarazatezalo/Documents/EPFL/semester%201/ml-project-1-girl-mse/Project1.ipynb#X25sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m y_tr_pred \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m sigmoid(x\u001b[39m.\u001b[39mT \u001b[39m@\u001b[39m w) \u001b[39m<\u001b[39m \u001b[39m0.5\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m x_train_pp])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sarazatezalo/Documents/EPFL/semester%201/ml-project-1-girl-mse/Project1.ipynb#X25sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mAccuracy on train test for our weights is: \u001b[39m\u001b[39m'\u001b[39m, accuracy_score(y_tr_pred, y_train_pp))\n",
      "File \u001b[0;32m~/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:271\u001b[0m, in \u001b[0;36mlogistic_regression\u001b[0;34m(y, tx, initial_w, max_iters, gamma)\u001b[0m\n\u001b[1;32m    268\u001b[0m w \u001b[39m=\u001b[39m initial_w\n\u001b[1;32m    269\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_iters):\n\u001b[1;32m    270\u001b[0m     \u001b[39m# get loss and update w\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m     loss, w \u001b[39m=\u001b[39m logistic_regression_step(y, tx, w, gamma)\n\u001b[1;32m    272\u001b[0m loss \u001b[39m=\u001b[39m calculate_logistic_loss(y, tx, w)\n\u001b[1;32m    273\u001b[0m \u001b[39mreturn\u001b[39;00m w, loss\n",
      "File \u001b[0;32m~/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:246\u001b[0m, in \u001b[0;36mlogistic_regression_step\u001b[0;34m(y, tx, w, gamma)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[39m\"\"\"returns the loss and updated weights according to gradient descent method.\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \n\u001b[1;32m    233\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[39m\u001b[39;00m\n\u001b[1;32m    242\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[39m# ***************************************************\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[39m# INSERT YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[39m# return loss, gradient, and Hessian: TODO\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m loss \u001b[39m=\u001b[39m calculate_logistic_loss(y, tx, w)\n\u001b[1;32m    247\u001b[0m w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m  gamma\u001b[39m*\u001b[39mcalculate_logistic_gradient(y, tx, w)\n\u001b[1;32m    248\u001b[0m \u001b[39m# ***************************************************\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:204\u001b[0m, in \u001b[0;36mcalculate_logistic_loss\u001b[0;34m(y, tx, w)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39m# ***************************************************\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m# INSERT YOUR CODE HERE\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[39m# TODO\u001b[39;00m\n\u001b[1;32m    203\u001b[0m N \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(y)\n\u001b[0;32m--> 204\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mdot(np\u001b[39m.\u001b[39mtranspose(y), np\u001b[39m.\u001b[39;49mdot(tx,w)) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39mlog(np\u001b[39m.\u001b[39mones(N,) \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mexp(np\u001b[39m.\u001b[39mdot(tx,w))))\n\u001b[1;32m    205\u001b[0m loss \u001b[39m/\u001b[39m\u001b[39m=\u001b[39m N\n\u001b[1;32m    206\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Predictions using logistic regression!\n",
    "initial_w = np.random.normal(0, 0.01, size=(x_train_pp.shape[1],))\n",
    "gamma = 0.01\n",
    "max_iters = 2000\n",
    "w, loss = logistic_regression(y_train_pp, x_train_pp, initial_w, max_iters, gamma)\n",
    "\n",
    "y_tr_pred = np.array([0 if sigmoid(x.T @ w) < 0.5 else 1 for x in x_train_pp])\n",
    "print('Accuracy on train test for our weights is: ', accuracy_score(y_tr_pred, y_train_pp))\n",
    "print('F1 score on train test for our best weights is: ', f1_score(y_tr_pred, y_train_pp, 0))\n",
    "print('F1 score on train test for our best weights is: ', f1_score(y_tr_pred, y_train_pp))\n",
    "\n",
    "y_prediction = np.array([-1 if sigmoid(x.T @ w) < 0.5 else 1 for x in x_test_pp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fae58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_prediction, \"prediction_05.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7569a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on KFold for the best model:  0.737384437596302\n",
      "Accuracy on train test for our weights is:  0.7376550342808721\n",
      "F1 score on train test for our best weights is:  0.7263449716742336\n",
      "F1 score on train test for our best weights is:  0.7480673201405585\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lambdas = np.logspace(-4, 1, 30)\n",
    "k_fold = 10\n",
    "best_lambda, best_acc, best_weights = best_cv_ridge_reg(y_train_pp, x_train_pp, k_fold, lambdas, seed=1)\n",
    "y_train_prediction = np.array([0 if x.T @ best_weights < 0.5 else 1 for x in x_train_pp])\n",
    "\n",
    "print('Accuracy on KFold for the best model: ', best_acc)\n",
    "print('Accuracy on train test for our weights is: ', accuracy_score(y_train_prediction, y_train_pp))\n",
    "print('F1 score on train test for our best weights is: ', f1_score(y_train_prediction, y_train_pp, 0))\n",
    "print('F1 score on train test for our best weights is: ', f1_score(y_train_prediction, y_train_pp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f84005",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_prediction = np.array([-1 if x.T @ best_weights < 0.5 else 1 for x in x_test_pp])\n",
    "create_csv_submission(test_ids, y_test_prediction, \"prediction_08.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64ef0f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.all((y_prediction==y_test_prediction)==True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a75c81e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.   1.   1.   4.   8.   9.  27.  16.  64.  25.\n",
      "  125.]\n",
      " [  2.   3.   4.   5.   6.   4.   8.   9.  27.  16.  64.  25. 125.  36.\n",
      "  216.]\n",
      " [  3.   4.   5.   6.   7.   9.  27.  16.  64.  25. 125.  36. 216.  49.\n",
      "  343.]]\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import *\n",
    "x_dummy = np.array([[1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7]])\n",
    "x_dummy = build_poly(x_dummy, 3)\n",
    "print(x_dummy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
