{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37a5deb5",
   "metadata": {},
   "source": [
    "## Importing used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21237998-1a1c-4363-bb8d-16b0c387c912",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "from preprocessing import preprocess_data, preprocess_data_relevant\n",
    "from implementations import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b930523-c9c4-4b69-a5e0-44e3caa05b2b",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "\n",
    "First, we are going to load the data that we'll feed to our alorithm in order for it to learn. We have 3 .csv files to import: <br> *x_train.csv*, *x_test.csv* and *y_train.csv*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1519b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"/Users/sarazatezalo/Documents/EPFL/semester 1/ML_course/projects/project1/data/dataset_to_release 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc48c4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values of class weights are- for class 0: 5.662381363244176 , for class 1: 0.5484272630030753\n"
     ]
    }
   ],
   "source": [
    "N_class1 = np.sum((y_train==1).astype(int))\n",
    "N_class0 = np.sum((y_train==-1).astype(int))\n",
    "N = len(y_train)\n",
    "w0 = N/2/N_class1\n",
    "w1 = N/2/N_class0\n",
    "print('Optimal values of class weights are- for class 0:', w0, ', for class 1:', w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ed6a9c",
   "metadata": {},
   "source": [
    "### 1) When preprocessed with the whole set of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "693c6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 142)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/utils.py:32: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  precision = tp / (tp + fp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values found are: best lambda: 0.0001, best gamma: 0.01, best weight for class 0: 0.85, for class 1: 1.5\n",
      "Best accuracy on 5-fold:  0.8585125024761151\n",
      "Best F1 score on 5-fold for class 1  0.3699477262617819\n"
     ]
    }
   ],
   "source": [
    "# Predictions using logistic regression!\n",
    "\n",
    "gammas = np.logspace(-5, -1, 5)\n",
    "lambdas = np.logspace(-4, -1, 5)\n",
    "w0s = [0.54, 0.7, 0.85, 0.9]\n",
    "w1s = [5.56, 3.5, 1.5, 1]\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data(x_train, y_train, x_test, neg_label=0)\n",
    "print(x_train_pp.shape)\n",
    "initial_w = np.zeros((x_train_pp.shape[1],))\n",
    "k_fold = 5\n",
    "max_iters = 25\n",
    "\n",
    "best_lambda, best_gamma, best_acc, best_weights, best_f1, best_w0, best_w1 = best_cv_log_reg(y_train_pp, x_train_pp, k_fold, lambdas, gammas, max_iters, w0s, w1s)\n",
    "\n",
    "print(f'Optimal values found are: best lambda: {best_lambda}, best gamma: {best_gamma}, best weight for class 0: {best_w0}, for class 1: {best_w1}')\n",
    "\n",
    "print(f'Best accuracy on {k_fold}-fold: ', best_acc)\n",
    "print(f'Best F1 score on {k_fold}-fold for class 1 ', best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c69ca25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 112)\n",
      "For the w0:0.55, and w1:1 we get F1 score of: 0.36998281302259894, and accuracy of: 0.8563182836332608\n",
      "For the w0:0.55, and w1:1.25 we get F1 score of: 0.36312478953531346, and accuracy of: 0.8722111326131012\n",
      "For the w0:0.55, and w1:1.5 we get F1 score of: 0.35025556122105733, and accuracy of: 0.8831121337254484\n",
      "For the w0:0.55, and w1:1.65 we get F1 score of: 0.340940801100984, and accuracy of: 0.8882228351135966\n",
      "For the w0:0.55, and w1:1.7 we get F1 score of: 0.3377265072660231, and accuracy of: 0.8896521248876225\n",
      "For the w0:0.55, and w1:2 we get F1 score of: 0.3133329428069812, and accuracy of: 0.896768098496046\n",
      "For the w0:0.55, and w1:3 we get F1 score of: 0.21038721711963312, and accuracy of: 0.9091806725890258\n",
      "For the w0:0.55, and w1:4 we get F1 score of: 0.10078628914685268, and accuracy of: 0.9118746857238635\n",
      "For the w0:0.6, and w1:1 we get F1 score of: 0.37174301322338377, and accuracy of: 0.8513751961844973\n",
      "For the w0:0.6, and w1:1.25 we get F1 score of: 0.36493085317774965, and accuracy of: 0.868157922806162\n",
      "For the w0:0.6, and w1:1.5 we get F1 score of: 0.3540904788236553, and accuracy of: 0.8797964252518019\n",
      "For the w0:0.6, and w1:1.65 we get F1 score of: 0.3464589184217803, and accuracy of: 0.8855471071357824\n",
      "For the w0:0.6, and w1:1.7 we get F1 score of: 0.34338365447060504, and accuracy of: 0.8871927712679234\n",
      "For the w0:0.6, and w1:2 we get F1 score of: 0.3207660348468759, and accuracy of: 0.8949700580553734\n",
      "For the w0:0.6, and w1:3 we get F1 score of: 0.2208995953963689, and accuracy of: 0.9085833574595821\n",
      "For the w0:0.6, and w1:4 we get F1 score of: 0.10953662963453321, and accuracy of: 0.9118106876742804\n",
      "For the w0:0.7, and w1:1 we get F1 score of: 0.37339828747216125, and accuracy of: 0.8412817895073674\n",
      "For the w0:0.7, and w1:1.25 we get F1 score of: 0.3701696353381044, and accuracy of: 0.8603806360187118\n",
      "For the w0:0.7, and w1:1.5 we get F1 score of: 0.36218731112895297, and accuracy of: 0.8736891828058575\n",
      "For the w0:0.7, and w1:1.65 we get F1 score of: 0.35559618349685235, and accuracy of: 0.8800493699239642\n",
      "For the w0:0.7, and w1:1.7 we get F1 score of: 0.3528989379284073, and accuracy of: 0.8819327410974142\n",
      "For the w0:0.7, and w1:2 we get F1 score of: 0.33366911577878666, and accuracy of: 0.8911576028159143\n",
      "For the w0:0.7, and w1:3 we get F1 score of: 0.23918388690272377, and accuracy of: 0.907032166638731\n",
      "For the w0:0.7, and w1:4 we get F1 score of: 0.1280753922951183, and accuracy of: 0.9116278361040425\n",
      "For the w0:0.75, and w1:1 we get F1 score of: 0.3731167083365049, and accuracy of: 0.8363996525820167\n",
      "For the w0:0.75, and w1:1.25 we get F1 score of: 0.3710632552205273, and accuracy of: 0.856290855897725\n",
      "For the w0:0.75, and w1:1.5 we get F1 score of: 0.3650730500321008, and accuracy of: 0.8706812744754446\n",
      "For the w0:0.75, and w1:1.65 we get F1 score of: 0.3586023264743362, and accuracy of: 0.8771176497478173\n",
      "For the w0:0.75, and w1:1.7 we get F1 score of: 0.3562907007769418, and accuracy of: 0.8791229219680925\n",
      "For the w0:0.75, and w1:2 we get F1 score of: 0.33935643229885554, and accuracy of: 0.8892193761713928\n",
      "For the w0:0.75, and w1:3 we get F1 score of: 0.2491629111445694, and accuracy of: 0.9064135188260929\n",
      "For the w0:0.75, and w1:4 we get F1 score of: 0.1382822569290487, and accuracy of: 0.9116004083685068\n",
      "For the w0:0.85, and w1:1 we get F1 score of: 0.37173838259641956, and accuracy of: 0.8267420421472871\n",
      "For the w0:0.85, and w1:1.25 we get F1 score of: 0.3732568725483649, and accuracy of: 0.848336812592378\n",
      "For the w0:0.85, and w1:1.5 we get F1 score of: 0.3684567465700454, and accuracy of: 0.8641900437320006\n",
      "For the w0:0.85, and w1:1.65 we get F1 score of: 0.3649131330197291, and accuracy of: 0.871784478949213\n",
      "For the w0:0.85, and w1:1.7 we get F1 score of: 0.36253052844409944, and accuracy of: 0.8738842244807777\n",
      "For the w0:0.85, and w1:2 we get F1 score of: 0.34870069709467727, and accuracy of: 0.8850229326344341\n",
      "For the w0:0.85, and w1:3 we get F1 score of: 0.265956073161109, and accuracy of: 0.9047952824294878\n",
      "For the w0:0.85, and w1:4 we get F1 score of: 0.15596445408125303, and accuracy of: 0.9112316577018603\n",
      "For the w0:0.9, and w1:1 we get F1 score of: 0.37109315259613324, and accuracy of: 0.8221494202081461\n",
      "For the w0:0.9, and w1:1.25 we get F1 score of: 0.3742331265697362, and accuracy of: 0.8445548326146252\n",
      "For the w0:0.9, and w1:1.5 we get F1 score of: 0.36998740435597355, and accuracy of: 0.8609718560958143\n",
      "For the w0:0.9, and w1:1.65 we get F1 score of: 0.36709230801066217, and accuracy of: 0.8690599905526689\n",
      "For the w0:0.9, and w1:1.7 we get F1 score of: 0.3650336750811376, and accuracy of: 0.8711536410318924\n",
      "For the w0:0.9, and w1:2 we get F1 score of: 0.35259382138390194, and accuracy of: 0.882901854419675\n",
      "For the w0:0.9, and w1:3 we get F1 score of: 0.2741945462779708, and accuracy of: 0.9040334008868302\n",
      "For the w0:0.9, and w1:4 we get F1 score of: 0.16531056159190136, and accuracy of: 0.9111310893382296\n",
      "For the w0:0.95, and w1:1 we get F1 score of: 0.3698670619081666, and accuracy of: 0.8174836576409099\n",
      "For the w0:0.95, and w1:1.25 we get F1 score of: 0.37402796185066467, and accuracy of: 0.8405747634357811\n",
      "For the w0:0.95, and w1:1.5 we get F1 score of: 0.37130445000895984, and accuracy of: 0.8576805278315327\n",
      "For the w0:0.95, and w1:1.65 we get F1 score of: 0.3687574806482631, and accuracy of: 0.8660703673792798\n",
      "For the w0:0.95, and w1:1.7 we get F1 score of: 0.36714413387484196, and accuracy of: 0.8686211467840981\n",
      "For the w0:0.95, and w1:2 we get F1 score of: 0.35630410548821734, and accuracy of: 0.8807228732076735\n",
      "For the w0:0.95, and w1:3 we get F1 score of: 0.2823347269447423, and accuracy of: 0.9032654242918312\n",
      "For the w0:0.95, and w1:4 we get F1 score of: 0.17431403370941106, and accuracy of: 0.9109360476633093\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0.001]\n",
    "gammas = [0.01]\n",
    "w0s = [0.55, 0.6, 0.7, 0.75, 0.85, 0.9, 0.95]\n",
    "w1s = [1, 1.25, 1.5, 1.65, 1.7, 2, 3, 4]\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data(x_train, y_train, x_test, neg_label=0)\n",
    "print(x_train_pp.shape)\n",
    "initial_w = np.zeros((x_train_pp.shape[1],))\n",
    "k_fold = 5\n",
    "max_iters = 25\n",
    "\n",
    "for w0 in w0s:\n",
    "    for w1 in w1s:\n",
    "       _, _, best_acc, _, best_f1, _, _ = best_cv_log_reg(y_train_pp, x_train_pp, k_fold, lambdas, gammas, max_iters, [w0], [w1])\n",
    "       print(f'For the w0:{w0}, and w1:{w1} we get F1 score of: {best_f1}, and accuracy of: {best_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32282b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 111)\n",
      "For the w0:0.55, and w1:1 we get F1 score of: 0.36993021210342264, and accuracy of: 0.8577079555670684\n",
      "For the w0:0.55, and w1:1.25 we get F1 score of: 0.3620314232474455, and accuracy of: 0.8729364438417114\n",
      "For the w0:0.55, and w1:1.5 we get F1 score of: 0.3490908067343088, and accuracy of: 0.883666783488503\n",
      "For the w0:0.55, and w1:1.7 we get F1 score of: 0.3358292634188623, and accuracy of: 0.8901305864964115\n",
      "For the w0:0.55, and w1:2 we get F1 score of: 0.3117181426118859, and accuracy of: 0.897121611531839\n",
      "For the w0:0.75, and w1:1 we get F1 score of: 0.37321040762893826, and accuracy of: 0.8376369482072927\n",
      "For the w0:0.75, and w1:1.25 we get F1 score of: 0.37076234202142916, and accuracy of: 0.8573879653191522\n",
      "For the w0:0.75, and w1:1.5 we get F1 score of: 0.36487539987891565, and accuracy of: 0.8715802946957807\n",
      "For the w0:0.75, and w1:1.7 we get F1 score of: 0.35554747106213536, and accuracy of: 0.8797994727779725\n",
      "For the w0:0.75, and w1:2 we get F1 score of: 0.3389072850086917, and accuracy of: 0.8897100278848644\n",
      "For the w0:0.85, and w1:1 we get F1 score of: 0.3719343802466151, and accuracy of: 0.8280585734529996\n",
      "For the w0:0.85, and w1:1.25 we get F1 score of: 0.37303206946098755, and accuracy of: 0.8495497280082892\n",
      "For the w0:0.85, and w1:1.5 we get F1 score of: 0.3678784272671421, and accuracy of: 0.8650555411644596\n",
      "For the w0:0.85, and w1:1.7 we get F1 score of: 0.3626594535674193, and accuracy of: 0.8747832447011138\n",
      "For the w0:0.85, and w1:2 we get F1 score of: 0.3490655662912495, and accuracy of: 0.8857909092294329\n",
      "For the w0:0.95, and w1:1 we get F1 score of: 0.3705978795385345, and accuracy of: 0.8191476069300745\n",
      "For the w0:0.95, and w1:1.25 we get F1 score of: 0.3742107470689705, and accuracy of: 0.8417724412208389\n",
      "For the w0:0.95, and w1:1.5 we get F1 score of: 0.3711119008986024, and accuracy of: 0.8587684946744479\n",
      "For the w0:0.95, and w1:1.7 we get F1 score of: 0.3669617731214333, and accuracy of: 0.8693860758529264\n",
      "For the w0:0.95, and w1:2 we get F1 score of: 0.3552656813890043, and accuracy of: 0.8812744754445578\n"
     ]
    }
   ],
   "source": [
    "lambdas = [0.001]\n",
    "gammas = [0.01]\n",
    "w0s = [0.55, 0.75, 0.85, 0.95]\n",
    "w1s = [1, 1.25, 1.5, 1.7, 2]\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data(x_train, y_train, x_test, neg_label=0)\n",
    "print(x_train_pp.shape)\n",
    "initial_w = np.zeros((x_train_pp.shape[1],))\n",
    "k_fold = 5\n",
    "max_iters = 25\n",
    "\n",
    "for w0 in w0s:\n",
    "    for w1 in w1s:\n",
    "       _, _, best_acc, _, best_f1, _, _ = best_cv_log_reg(y_train_pp, x_train_pp, k_fold, lambdas, gammas, max_iters, [w0], [w1])\n",
    "       print(f'For the w0:{w0}, and w1:{w1} we get F1 score of: {best_f1}, and accuracy of: {best_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dcded54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(109379,)\n"
     ]
    }
   ],
   "source": [
    "# Prediction using best parameters and ridge logistic regression\n",
    "y_prediction = np.array([-1 if sigmoid(x.T @ best_weights) < 0.5 else 1 for x in x_test_pp])\n",
    "print(y_prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1f781b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are this much -1s:  93246\n",
      "There are this much 1s:  16133\n"
     ]
    }
   ],
   "source": [
    "print('There are this much -1s: ', np.sum((y_prediction==-1).astype(int)))\n",
    "print('There are this much 1s: ', np.sum((y_prediction==1).astype(int)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fae58d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, y_prediction, \"prediction_18.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b2be77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 156)\n",
      "Best accuracy on 5-fold:  0.8422996632483581\n",
      "Best F1 score on 5-fold for class 1  0.3461833326817825\n"
     ]
    }
   ],
   "source": [
    "# For best parameters, different preprocessing - added the expansion with pairs for random 10 features\n",
    "\n",
    "gammas = np.logspace(-5, -1, 5)\n",
    "lambdas = np.logspace(-4, -1, 5)\n",
    "w0s = [0.85]\n",
    "w1s = [1.5]\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data(x_train, y_train, x_test, neg_label=0)\n",
    "print(x_train_pp.shape)\n",
    "initial_w = np.zeros((x_train_pp.shape[1],))\n",
    "k_fold = 5\n",
    "max_iters = 50\n",
    "\n",
    "best_lambda, best_gamma, best_acc, best_weights, best_f1, best_w0, best_w1 = best_cv_log_reg(y_train_pp, x_train_pp, k_fold, lambdas, gammas, max_iters, w0s, w1s)\n",
    "\n",
    "print(f'Best accuracy on {k_fold}-fold: ', best_acc)\n",
    "print(f'Best F1 score on {k_fold}-fold for class 1 ', best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7569a73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on KFold for the best model:  0.9052188885672056\n",
      "F1 on KFold for the best model:  0.2177996772608644\n"
     ]
    }
   ],
   "source": [
    "# Prediction using ridge linear regression\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data(x_train, y_train, x_test, neg_label=-1)\n",
    "lambdas = np.logspace(-4, 0, 10)\n",
    "k_fold = 5\n",
    "best_lambda, best_acc, best_weights, best_f1 = best_cv_ridge_reg(y_train_pp, x_train_pp, k_fold, lambdas)\n",
    "y_train_prediction = np.array([-1 if x.T @ best_weights < 0 else 1 for x in x_train_pp])\n",
    "\n",
    "print('Accuracy on KFold for the best model: ', best_acc)\n",
    "print('F1 on KFold for the best model: ', best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b89509d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on KFold for the best model:  0.9071814954210918\n",
      "F1 on KFold for the best model:  0.27084897363875127\n"
     ]
    }
   ],
   "source": [
    "# Prediction using ridge linear regression with expansion with pairs of random 10 featues\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data(x_train, y_train, x_test, neg_label=-1)\n",
    "lambdas = np.logspace(-4, 0, 10)\n",
    "k_fold = 5\n",
    "best_lambda, best_acc, best_weights, best_f1 = best_cv_ridge_reg(y_train_pp, x_train_pp, k_fold, lambdas)\n",
    "y_train_prediction = np.array([-1 if x.T @ best_weights < 0 else 1 for x in x_train_pp])\n",
    "\n",
    "print('Accuracy on KFold for the best model: ', best_acc)\n",
    "print('F1 on KFold for the best model: ', best_f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b99c3",
   "metadata": {},
   "source": [
    "### 2) When preprocessed with a set of relevant features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "456fefcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(328135, 109)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:186: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-t))\n",
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:208: RuntimeWarning: divide by zero encountered in log\n",
      "  5.66 * y * np.log(sigmoid(tx.dot(w))) + 0.54 * (1 - y) * (np.log(1 - sigmoid(tx.dot(w))))\n",
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/implementations.py:208: RuntimeWarning: invalid value encountered in multiply\n",
      "  5.66 * y * np.log(sigmoid(tx.dot(w))) + 0.54 * (1 - y) * (np.log(1 - sigmoid(tx.dot(w))))\n",
      "/Users/sarazatezalo/Documents/EPFL/semester 1/ml-project-1-girl-mse/utils.py:34: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  f1 = 2 * (precision * recall)/(precision+recall)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal values found are: best lambda: 0.0031622776601683794, best gamma: 0.1, best weight for class 0: 0.85, for class 1: 1.5\n",
      "Best accuracy on 5-fold:  0.9035549392780411\n",
      "Best F1 score on 5-fold for class 1  0.1033976046939479\n"
     ]
    }
   ],
   "source": [
    "# Predictions using logistic regression!\n",
    "\n",
    "gammas = np.logspace(-5, -1, 3)\n",
    "lambdas = np.logspace(-4, -1, 3)\n",
    "w0s = [0.54, 0.7, 0.85, 0.9]\n",
    "w1s = [5.56, 3.5, 1.5, 1]\n",
    "\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data_relevant(x_train, y_train, x_test, neg_label=0)\n",
    "print(x_train_pp.shape)\n",
    "initial_w = np.zeros((x_train_pp.shape[1],))\n",
    "k_fold = 5\n",
    "max_iters = 25\n",
    "\n",
    "best_lambda, best_gamma, best_acc, best_weights, best_f1, best_w0, best_w1 = best_cv_log_reg(y_train_pp, x_train_pp, k_fold, lambdas, gammas, max_iters, w0s, w1s)\n",
    "\n",
    "print(f'Optimal values found are: best lambda: {best_lambda}, best gamma: {best_gamma}, best weight for class 0: {best_w0}, for class 1: {best_w1}')\n",
    "\n",
    "print(f'Best accuracy on {k_fold}-fold: ', best_acc)\n",
    "print(f'Best F1 score on {k_fold}-fold for class 1 ', best_f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee106f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on KFold for the best model:  0.912813323784418\n",
      "F1 on KFold for the best model:  0.05572685097485919\n"
     ]
    }
   ],
   "source": [
    "# Predictions using ridge linear regression\n",
    "x_train_pp, x_test_pp, y_train_pp = preprocess_data_relevant(x_train, y_train, x_test, neg_label=-1)\n",
    "\n",
    "lambdas = np.logspace(-4, 0, 10)\n",
    "k_fold = 5\n",
    "best_lambda, best_acc, best_weights, best_f1 = best_cv_ridge_reg(y_train_pp, x_train_pp, k_fold, lambdas)\n",
    "y_train_prediction = np.array([-1 if x.T @ best_weights < 0 else 1 for x in x_train_pp])\n",
    "\n",
    "print('Accuracy on KFold for the best model: ', best_acc)\n",
    "print('F1 on KFold for the best model: ', best_f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
